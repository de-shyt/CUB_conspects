{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d2049b1",
   "metadata": {},
   "source": [
    "# Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb90ff",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "\n",
    "We are given a set of coefficients. We want to try different methods to find a set of coefficients for the linear model that approximates the given coefficients. \n",
    "\n",
    "We are going to generate $m$ examples, each of them consists of $n$ features. \n",
    "\n",
    "In our exmples, $n = 3$. Each label (a target value a.k.a $y$) will look like $1  x_0 + 2 x_1 + 3 x_2 + \\texttt{noise}$. We add noise to make the task a bit harder for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45436c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "\"\"\"\n",
    "Generates training dataset\n",
    "- `A` is an array of given coefficients\n",
    "- `m` is the number of exmaples to generate\n",
    "- `noise` is the scale of noise that will be added to the target variable \n",
    "to make the data more realistic.\n",
    "\"\"\"\n",
    "def generate_data(A, m, noise):\n",
    "    n = len(A)\n",
    "    X = np.random.normal(0, 1, (m, n))\n",
    "    y = np.dot(X, A) + np.random.normal(0, noise, m)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_train, y_train = generate_data([1, 2, 3], 1000, 0.01)\n",
    "# X_test, y_test = generate_data([1, 2, 3], 100, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad98f7f",
   "metadata": {},
   "source": [
    "## Solve with Moore-Penrose inverse method\n",
    "\n",
    "We want to solve the equation $Xa = y$ => $a = X^{-1}y$. If $X$ is not inverse, use $a = (X^TX)^{-1}X^Ty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd724af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99927233 1.9999575  2.99962469]\n"
     ]
    }
   ],
   "source": [
    "def solve_pseudo_inverse(X, y):\n",
    "    matrix = np.linalg.inv(np.dot(X.T, X))\n",
    "    return np.dot(np.dot(matrix, X.T), y)\n",
    "\n",
    "print(solve_pseudo_inverse(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4370b2b2",
   "metadata": {},
   "source": [
    "As you can see, w got coefficients that are really close to the initial coefs `[1, 2, 3]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c615c6d3",
   "metadata": {},
   "source": [
    "## Solve using `LinearRegression` model\n",
    "\n",
    "`solve_sklearn` uses `LinearRegression` model to fit the training data and find the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59754295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99926323 1.99995834 2.99961724]\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def solve_sklearn(X, y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    print(model.coef_)\n",
    "\n",
    "\n",
    "solve_sklearn(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f15d5f",
   "metadata": {},
   "source": [
    "## Solve using the Stochastic Gradient Descent function\n",
    "\n",
    "We can use a loss function $L = (y_{pred} - y_{real})^2 = (\\sum\\limits_0^{n-1}a_ix_i - y_{real})^2$. We are going to use the gradient of the loss function. The gradient is a matrix consisting of such derivatives: $\\frac{\\Delta L}{\\Delta a_i} = L'_{a_i} = 2 (a_0x_0+...+a_{n-1}x_{n-1} - y_{real}) x_i$\n",
    "\n",
    "The `solve_sgd` function first initializes vector `a` with zeros and iteratively updates it in order to minimize the loss function error. In each iteration, it computes the prediction t, computes the gradient for the current vector `a` and updates the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd2e9c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99927233 1.99995746 2.99962465]\n"
     ]
    }
   ],
   "source": [
    "def solve_sgd(X, y, iterations, learning_rate):\n",
    "    n = X.shape[1]\n",
    "    a = np.zeros(n)\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        t = np.dot(X, a)\n",
    "        t = 2 * (t - y) * X.T\n",
    "        t = np.mean(t, axis = 1)\n",
    "        a -= t * learning_rate\n",
    "    return a\n",
    "    \n",
    "print (solve_sgd(X_train, y_train, 1000, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a467cb",
   "metadata": {},
   "source": [
    "`np.mean(t, axis = 1)` finds the average over all examples in the dataset. \n",
    "\n",
    "`learning_rate` is a hyperparameter that controls the size of steps taken during the optimization process. Typically, it is a positive number between $0$ and $1$ that scales the gradient before applying it to update coefficients. The learning rate determines the step size in the direction of the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f222b9",
   "metadata": {},
   "source": [
    "## Check for overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5e4892",
   "metadata": {},
   "source": [
    "todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02c7dd5",
   "metadata": {},
   "source": [
    "# Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9992bf65",
   "metadata": {},
   "source": [
    "## Boosting tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78fb9ff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a837bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
